<!DOCTYPE html><html lang="en" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="generator" content="Jekyll v4.2.2" /><meta property="og:title" content="Emergence: Memory management" /><meta property="og:locale" content="en" /><meta name="description" content="It is very important to have consistent memory model for your project from the start, because it is almost impossible to change it later. In this post I will talk about Emergence memory management library and its design decisions." /><meta property="og:description" content="It is very important to have consistent memory model for your project from the start, because it is almost impossible to change it later. In this post I will talk about Emergence memory management library and its design decisions." /><link rel="canonical" href="/posts/EmergenceMemoryManagement/" /><meta property="og:url" content="/posts/EmergenceMemoryManagement/" /><meta property="og:site_name" content="WHAT KIND OF DEV ARE YOU" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2022-08-09T09:30:00+03:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="Emergence: Memory management" /><meta name="twitter:site" content="@twitter_username" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2022-08-09T09:30:00+03:00","datePublished":"2022-08-09T09:30:00+03:00","description":"It is very important to have consistent memory model for your project from the start, because it is almost impossible to change it later. In this post I will talk about Emergence memory management library and its design decisions.","headline":"Emergence: Memory management","mainEntityOfPage":{"@type":"WebPage","@id":"/posts/EmergenceMemoryManagement/"},"url":"/posts/EmergenceMemoryManagement/"}</script><title>Emergence: Memory management | WHAT KIND OF DEV ARE YOU</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="WHAT KIND OF DEV ARE YOU"><meta name="application-name" content="WHAT KIND OF DEV ARE YOU"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link rel="dns-prefetch" href="https://fonts.gstatic.com" crossorigin><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://cdn.jsdelivr.net" ><link rel="dns-prefetch" href="https://cdn.jsdelivr.net" ><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato&family=Source+Sans+Pro:wght@400;600;700;900&display=swap"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get MODE_ATTR() { return "data-mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } static get ID() { return "mode-toggle"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } let self = this; /* always follow the system prefers */ this.sysDarkPrefers.addEventListener("change", () => { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.notify(); }); } /* constructor() */ get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode === ModeToggle.DARK_MODE; } get isLightMode() { return this.mode === ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer)) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } setDark() { $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_ATTR); sessionStorage.removeItem(ModeToggle.MODE_KEY); } /* Notify another plugins that the theme mode has changed */ notify() { window.postMessage({ direction: ModeToggle.ID, message: this.modeStatus }, "*"); } } /* ModeToggle */ const toggle = new ModeToggle(); function flipMode() { if (toggle.hasMode) { if (toggle.isSysDarkPrefer) { if (toggle.isLightMode) { toggle.clearMode(); } else { toggle.setLight(); } } else { if (toggle.isDarkMode) { toggle.clearMode(); } else { toggle.setDark(); } } } else { if (toggle.isSysDarkPrefer) { toggle.setLight(); } else { toggle.setDark(); } } toggle.notify(); } /* flipMode() */ </script><body data-spy="scroll" data-target="#toc" data-topbar-visible="true"><div id="sidebar" class="d-flex flex-column align-items-end"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" class="mx-auto"> <img src="/assets/img/avatar.png" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">WHAT KIND OF DEV ARE YOU</a></div><div class="site-subtitle font-italic">Personal blog above Game Development and related things</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info-circle ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tag ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center"> <button class="mode-toggle btn" aria-label="Switch Mode"> <i class="fas fa-adjust"></i> </button> <span class="icon-border"></span> <a href="https://github.com/KonstantinTomashevich" aria-label="github" target="_blank" rel="noopener"> <i class="fab fa-github"></i> </a> <a href="https://t.me/WhatKindOfDevAreYou" aria-label="telegram" target="_blank" rel="noopener"> <i class="fab fa-telegram"></i> </a> <a href="https://t.me/KonstantinTomashevich" aria-label="telegram" target="_blank" rel="noopener"> <i class="fab fa-telegram"></i> </a> <a href="https://www.linkedin.com/in/konstantin-tomashevich-1881aa152/" aria-label="linkedin" target="_blank" rel="noopener"> <i class="fab fa-linkedin"></i> </a> <a href="/feed.xml" aria-label="rss" > <i class="fas fa-rss"></i> </a></div></div><div id="topbar-wrapper"><div id="topbar" class="container d-flex align-items-center justify-content-between h-100 pl-3 pr-3 pl-md-4 pr-md-4"> <span id="breadcrumb"> <span> <a href="/"> Home </a> </span> <span>Emergence: Memory management</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper" class="d-flex justify-content-center"><div id="main" class="container pl-xl-4 pr-xl-4"><div class="row"><div id="core-wrapper" class="col-12 col-lg-11 col-xl-9 pr-xl-4"><div class="post pl-1 pr-1 pl-md-2 pr-md-2"><h1 data-toc-skip>Emergence: Memory management</h1><div class="post-meta text-muted"> <span> Posted <em class="" data-ts="1660026600" data-df="ll" data-toggle="tooltip" data-placement="bottom"> Aug 9, 2022 </em> </span><div class="d-flex justify-content-between"> <span> By <em> <a href="https://github.com/KonstantinTomashevich">Konstantin Tomashevich</a> </em> </span><div> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="4098 words"> <em>22 min</em> read</span></div></div></div><div class="post-content"><p>It is very important to have consistent memory model for your project from the start, because it is almost impossible to change it later. In this post I will talk about <a href="https://github.com/KonstantinTomashevich/Emergence">Emergence</a> memory management library and its design decisions.</p><h3 id="motivation"><span class="mr-2">Motivation</span><a href="#motivation" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>Having the right approach to managing memory is crucial for performance: it impacts both allocation cost and cache coherency. Of course, you can just allocate all the memory on heap by using new, but it will lead to slow allocation, cache misses and memory fragmentation. In my opinion, game engine without consistent memory management model is like giant with legs made of straw. Therefore, I decided that <a href="https://github.com/KonstantinTomashevich/Emergence">Emergence</a> must be built on top of consistent memory library from the very beginning. Furthermore, I’ve decided to write my own memory management library to have full control on how memory allocation works.</p><p>Writing your own memory management library is not a walk in the park and it’s quite easy to get lost in details. For example, if you’re committed enough, you can try to ignore the existence of C standard library allocation functions and write your own platform-specific versions. But it is a tedious and troublesome task. I’ve decided to be less thorough about that and primarily focus on the API instead of implementation details: once API is done right and whole project uses it, it shouldn’t be difficult to change implementation details under the hood.</p><p>One important part about memory management model is that it should not only be consistent and easy to use, but also provide tools for memory usage analysis, for example custom profiler. Having such tools is important because they allow us to visualize how we’re using memory and provide us with insight on what can be improved. When I was searching for such tool to integrate into my memory management library, I’ve mostly encountered tools that track memory allocations by file name or by one of the static predefined tags. It looked like it is not good enough for <a href="https://github.com/KonstantinTomashevich/Emergence">Emergence</a>: I wanted to be able to build dynamic memory usage flame graph and none of the tools I found was fully capable of doing so. Therefore I’ve decided that I need to write my own tool.</p><p>To summarize, I’ve decided to follow these principles:</p><ul><li>The most important part is consistent and easy-to-use API.<li>C standard library functions is a good enough backend for the beginning.<li>Library must provide API and a tool for memory usage profiling and analysis.</ul><h3 id="features"><span class="mr-2">Features</span><a href="#features" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>It is important to have a rich enough feature set. It should be neither too small nor too big: it should provide enough control on how memory is allocated, but user must not sink in the sea of details. I’ve decided to go with this feature set for <a href="https://github.com/KonstantinTomashevich/Emergence">Emergence</a> memory management library:</p><ul><li>Unordered pool allocator for lighting-fast allocation and deallocation of objects of the same type.<li>Ordered pool allocator, that has slow deallocation operation, but is more cache coherent and provides iteration over allocated chunks.<li>Stack allocator for lighting-fast cache-coherent allocation of temporary trivial objects.<li>Heap allocator for general purpose allocation.<li>String interning implementation for ASCII strings.</ul><p>It’s better to provide memory usage profiler features as separate list to avoid blending with memory management features:</p><ul><li>Memory usage is tracked for logical groups that can be created at any moment during runtime.<li>Memory usage snapshot for all logical groups can be taken at any moment of time. It makes sampling-based profiling possible.<li>Profiler should be able to represent all memory operations as continuous set of events. It makes instrumentation-based profiling possible.<li>There should be an API for serializing and deserializing memory usage tracks: initial memory snapshot and continuous set of events that happened after this snapshot.<li>There should be a tool for viewing memory tracks.</ul><p>Initially I also wanted to implement client-server profiler like <a href="https://github.com/wolfpld/tracy">Tracy</a>, but I’ve decided to postpone it. It is not so difficult, but it requires time and I’ve decided that it is better to spend this time on other <a href="https://github.com/KonstantinTomashevich/Emergence">Emergence</a> libraries.</p><h3 id="allocators"><span class="mr-2">Allocators</span><a href="#allocators" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><h4 id="pool"><span class="mr-2">Pool</span><a href="#pool" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4><p>Pool allocators manage memory in terms of chunks and pages. Chunk is a memory block of predefined size which is usually selected during allocator construction. Page is a large continuous block of chunks. Pages are organized into linked list: each page contains pointer to the next one. Chunks can either be used or unused: used chunks contain user-defined data and free chunks are organized into free-chunk linked list – every free chunk contains pointer to the next one. To sum up, referencing looks like this:</p><p><img data-src="/assets/img/EmergenceMemoryManagement/PoolAllocator.png" alt="Pool allocator pages and pointers" data-proofer-ignore></p><p>When user requests new chunk from the allocator, we start by checking whether free chunk list is empty. If it’s not empty, we can just pop the first chunk out of this list and return it to user. If there is no free chunks left, we need to allocate new page and put all the chunks from this page into free chunk list.</p><p>When user reports that he no longer uses given chunk, we can just put this chunk back into free chunks list and that’s all! But there is one important question: are we putting this chunk into the beginning of free chunk list or into other place? This question defines main algorithmic difference between ordered and unordered pools. Basically, ordered pool guarantees that page list and free chunk list are sorted by addresses in ascending order. You can see that image above illustrates ordered pool. This ordering provides several benefits:</p><ul><li>Memory allocation is more cache coherent as free chunk list ordering minimizes amount of holes between used chunks.<li>Pool shrinking (deallocation of fully unused pages) can be implemented effectively: it can be done in O(pageCount + freeChunkCount) instead of O(pageCount * pageCapacity * freeChunkCount), because we do not need to iterate over all free chunk list to determinate whether chunk is free.<li>Iteration over used chunks can be implemented effectively for the same reason.</ul><p>However, ordering is not a silver bullet, because it has one important flaw: it makes release operation (when user informs that chunk is no longer used) O(freeChunksCount) – we need to find suitable place for new chunk in the list. This can introduce significant performance drops if we’re releasing lots of chunks in a random order. Therefore, usage of ordered or unordered pool is always a trade-off and memory usage strategy should be considered thoroughly before selecting one pool type over another.</p><p><a href="https://github.com/KonstantinTomashevich/Emergence/tree/e8c37b6/Service/Memory">Emergence::Memory service</a> provides both type of pools as separate classes: <code class="language-plaintext highlighter-rouge">OrderedPool</code> and <code class="language-plaintext highlighter-rouge">UnorderedPool</code>. This allows user to select pool algorithm with zero runtime overhead. They both provide this set of operations:</p><ul><li><code class="language-plaintext highlighter-rouge">Acquire</code> requests new chunk from the pool.<li><code class="language-plaintext highlighter-rouge">Release</code> returns chunk that is no longer used to the pool.<li><code class="language-plaintext highlighter-rouge">IsEmpty</code> checks whether pool has any used chunk.<li><code class="language-plaintext highlighter-rouge">Clear</code> deallocates all pages altogether.</ul><p>In addition, <code class="language-plaintext highlighter-rouge">OrderedPool</code> supports these operations:</p><ul><li>Iteration over acquired (used) chunks through <code class="language-plaintext highlighter-rouge">BeginAcquired</code>/<code class="language-plaintext highlighter-rouge">EndAcquired</code>.<li><code class="language-plaintext highlighter-rouge">Shrink</code> deallocates all pages that have no used chunks.</ul><p>It is worth mentioning that both pools support custom chunk alignment that can be specified during allocator creation.</p><p>In the end, let’s go over the pros and cons of pool allocator usage.</p><p>Pros:</p><ul><li>Generally faster allocation and deallocation: operations on free chunk list are much more lightweight than operations on complex heap allocator structures.<li>Protection from memory fragmentation: on the top level allocator works with big memory blocks (pages) instead of small blocks and that reduces risk of memory fragmentation by a lot.<li>Cache coherency: chunks are allocated on continuous blocks of memory (pages), therefore in most cases logically adjacent data will be stored in adjacent memory addresses.</ul><p>Cons:</p><ul><li>You need to manually shrink/clear pool allocators if your memory usage strategy is not stable. For example, you may allocate lots of chunks for temporary objects during level loading and you will no longer need this data after level is loaded, so you need to manually clear or shrink that pool.<li>Pool allocators only work for fixed size chunks with size greater or equal to the size of pointer. If you need variable-size cache coherent allocations or need to allocate smaller blocks of memory you need to use other approach.</ul><h4 id="stack"><span class="mr-2">Stack</span><a href="#stack" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4><p>Stack allocators usually operate on preallocated block of memory and provide memory in a stack-like fashion by increasing stack top pointer. At the beginning stack top pointer looks at first byte of allocator-managed memory region. Each allocation is done by moving stack top pointer forward. Deallocations are done by moving this pointer backward. You can already see the problem in this pattern: deallocation can not be done in random order. That’s true: there is no canonical deallocation in stack allocator API, instead there is return-to-checkpoint operation, that moves stack top pointer to saved position from the past. This operation deallocates everything that was allocated after checkpoint.</p><p><img data-src="/assets/img/EmergenceMemoryManagement/StackAllocator.png" alt="Stack allocator block" data-proofer-ignore></p><p><a href="https://github.com/KonstantinTomashevich/Emergence/tree/e8c37b6/Service/Memory">Emergence::Memory service</a> provides implementation of this type of allocator through <code class="language-plaintext highlighter-rouge">Stack</code> class. It preallocates memory block of given capacity and operates on top of this block. <code class="language-plaintext highlighter-rouge">Stack</code> supports following operations:</p><ul><li><code class="language-plaintext highlighter-rouge">Acquire</code> – allocates given amount of bytes with given alignment and moves stack top forward.<li><code class="language-plaintext highlighter-rouge">Head</code> – returns stack top pointer that can be saved and used as checkpoint later.<li><code class="language-plaintext highlighter-rouge">Release</code> – moves stack top pointer back to given checkpoint.<li><code class="language-plaintext highlighter-rouge">Clear</code> – moves stack top pointer back to the beginning.<li><code class="language-plaintext highlighter-rouge">GetFreeSpace</code> – returns how much space is left to be used.</ul><p>Stack allocators are simple and powerful, but also usually a niche solution. Let’s go over its pros and cons.</p><p>Pros:</p><ul><li>Lighting-fast allocation: nothing can be faster than one simple pointer operation.<li>Lighting-fast mass-deallocation: we can deallocate all object in one pointer operation without updating anything except stack top pointer.<li>Does not cause memory fragmentation: stack only preallocates memory during construction and never actually allocates memory from heap after that.</ul><p>Cons:</p><ul><li>Stack allocator is only suitable for trivially-destructible objects due to its mass-deallocation approach.<li>Stack operates on fixed amount of memory and can never grow bigger than predefined capacity.<li>Stack does not support selective deallocation: you either deallocate everything by reverting to a checkpoint or deallocate nothing.</ul><p>To sum up, stack allocator is one of the best examples of niche solutions. It is almost completely unusable for general purpose situations, but is very helpful for some special cases. For example, it is a usual solution for temporary trivial objects with one-frame lifetime: during frame all systems than need such objects request memory for them though stack allocator and when frame ends these objects are easily deallocated all-at-once.</p><h4 id="heap"><span class="mr-2">Heap</span><a href="#heap" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4><p>Heap allocators theme is quite interesting from technological point of view and it deserves a separate article for sure! But in <a href="https://github.com/KonstantinTomashevich/Emergence">Emergence</a> I’ve decided to avoid inventing my own bicycle, which is quite rare as I’m almost always inventing my own bicycles, and use <code class="language-plaintext highlighter-rouge">malloc</code>, <code class="language-plaintext highlighter-rouge">realloc</code> and <code class="language-plaintext highlighter-rouge">free</code> under the hood of <code class="language-plaintext highlighter-rouge">Heap</code> wrapper-class. Heap allocators are universal generic solution, but there are reasons for the existence of other allocators, so let’s go over pros and cons of this allocator type.</p><p>Pros:</p><ul><li>Universal: allocate whatever you want whenever you want.</ul><p>Cons:</p><ul><li>Slower than specialized allocators, like pool and stack allocators.<li>Has high risk of memory fragmentation when lots of small objects are allocated and deallocated.</ul><h3 id="string-interning"><span class="mr-2">String interning</span><a href="#string-interning" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>String interning is an important technique that allows to both save the memory and improve application performance if you use it right. Interned strings are stored in a special pool and are never duplicated. That makes equality check, hash calculation and string copying lighting fast, because interned string object is essentially just a pointer to the real string in interned strings pool. But it also slows down string creation from raw values, because it adds string interning pass to construction routine.</p><p><a href="https://github.com/KonstantinTomashevich/Emergence/tree/e8c37b6/Service/Memory">Emergence::Memory service</a> provides string interning implementation for ASCII strings through <code class="language-plaintext highlighter-rouge">UniqueString</code> class. Let’s take a quick look at how interned strings pool is organized there.</p><p><img data-src="/assets/img/EmergenceMemoryManagement/StringInterning.png" alt="String interning memory structure" data-proofer-ignore></p><p>Instead of spreading strings all over the memory (which would cause memory fragmentation), we’re storing them in special memory structure: pool of string stacks. It is essentially pool allocator of stack allocators that are used to allocate interned string values. When current string stack is filled we allocate new stack and continue to allocate strings through it. Interned strings are never deallocated as it makes interning logic more performant and easy-to-use. To check whether string value is already interned or not we keep separate hash set of strings that hashes interned strings by their values instead of their pointers. It allows us to do this check in almost O(stringLength), but, of course, eats additional memory.</p><p>As every other memory-related solution, string interning is not a silver bullet and has its pros and cons.</p><p>Pros:</p><ul><li>Provides lighting-fast equality check, hash calculation and string copying.<li>Guarantees that strings are not duplicated in memory.</ul><p>Cons:</p><ul><li>Most implementations store interned values for whole program execution, therefore temporary strings should never be interned.<li>Interning is not a fast operation, so it should not be called every frame and should not be called on temporary strings.</ul><p>Implementing your own string interning library is much easier than it sounds! If you wanna try, check out <a href="/posts/TutorialStringInterning/">my article</a> about implementation of trivial string interning routine.</p><h3 id="profiling"><span class="mr-2">Profiling</span><a href="#profiling" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>It’s important to understand how your memory model scales as the project growth and good memory profiler is crucial to achieve this goal. Good memory profiler provides developers with tools that allow to see the big picture and to identify problems early. I’ve decided that I need following features from <a href="https://github.com/KonstantinTomashevich/Emergence">Emergence</a> memory profiling:</p><ul><li>It should be instrumental, but still reasonably fast and lightweight. Instrumental profiling would allow us to track every memory operation and find even the smallest bad patterns like continuous allocation and deallocation in one particular task every frame.<li>It should be able to differentiate between used and reserved memory. <a href="https://github.com/KonstantinTomashevich/Emergence">Emergence</a> uses pool allocators a lot so it is very important to see whether memory is used or reserved for future usage.<li>It should be able to provide memory usage flame graph at any particular moment of time. Flame graphs are quite useful, because they allow to easily switch from bigger picture to details and vice versa. For example, it could be easy to see that particular component storage consumes too much memory, because it is too wide. Flame graph allows us to go further into to see what actually consumes memory: for example, component data or indices. Image below shows that indices of <code class="language-plaintext highlighter-rouge">StaticModelComponent</code> consume half of the storage memory!</ul><p><img data-src="/assets/img/EmergenceMemoryManagement/FlameGraphExample.png" alt="String interning memory structure" data-proofer-ignore></p><ul><li>It should provide an API for implicit hierarchy creation. For example, let’s imagine that we have a <code class="language-plaintext highlighter-rouge">Storage</code> library and a <code class="language-plaintext highlighter-rouge">StorageManager</code> library. <code class="language-plaintext highlighter-rouge">Storage</code> knowns nothing of <code class="language-plaintext highlighter-rouge">StorageManager</code>, but it should be a child of <code class="language-plaintext highlighter-rouge">StorageManager</code> on flame graph. So, there should be a way to pass this hierarchical dependency to <code class="language-plaintext highlighter-rouge">Storage</code> implicitly, without explicitly adding knowledge of <code class="language-plaintext highlighter-rouge">StorageManager</code>.</ul><p>I didn’t find any ready-to-integrate solution that has all these features at once, therefore I’ve decided to write my own memory profiling solution and integrate it with <a href="https://github.com/KonstantinTomashevich/Emergence/tree/e8c37b6/Service/Memory">Emergence::Memory</a> allocators. Also, I’ve chosen to separate this solution into 3 parts: profiling backend, that is directly integrated with <a href="https://github.com/KonstantinTomashevich/Emergence/tree/e8c37b6/Service/Memory">Emergence::Memory service</a>, runtime tracking library with serialization support and client application. I’ll describe each part separately.</p><h4 id="profiling-backend"><span class="mr-2">Profiling backend</span><a href="#profiling-backend" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4><p><a href="https://github.com/KonstantinTomashevich/Emergence/tree/e8c37b6/Service/MemoryProfiler">Emergence::MemoryProfiler service</a> is used as profiling backend: it implements memory usage calculations, registers operations and provides low-level capture API. It was intentionally separated from <a href="https://github.com/KonstantinTomashevich/Emergence/tree/e8c37b6/Service/Memory">Emergence::Memory service</a> for two reasons:</p><ul><li>We need to be able to disable memory profiling in release builds by selecting special empty implementation and that should not affect memory allocators implementation selection.<li>Profiling logic is not technically coupled with allocation logic, so there is no sense to introduce coupling by merging them into one service.</ul><p>The heart of the profiling backend is <code class="language-plaintext highlighter-rouge">AllocationGroup</code> class which provides API for memory operations registration. <code class="language-plaintext highlighter-rouge">AllocationGroup</code> is not only a registration API provider, but also is a part of memory usage hierarchy: groups are organized into tree graph with predefined <code class="language-plaintext highlighter-rouge">Root</code> group as tree root. Every <code class="language-plaintext highlighter-rouge">AllocationGroup</code> stores its id, reserved memory amount, used memory amount and pointers to parent, first child and next on level groups. Although referencing model might look a bit weird, it allows us to avoid usage of complex containers. Picture below illustrates how <code class="language-plaintext highlighter-rouge">AllocationGroup</code> referencing looks like.</p><p><img data-src="/assets/img/EmergenceMemoryManagement/AllocationGroupReferencing.png" alt="Allocation group referencing" data-proofer-ignore></p><p><code class="language-plaintext highlighter-rouge">AllocationGroup</code>s themselves are allocated through unprofiled <code class="language-plaintext highlighter-rouge">OrderedPool</code>. Of course, it is impossible to profile how much memory profiling takes, because it would introduce cyclic dependency in initialization order. Usage of <code class="language-plaintext highlighter-rouge">OrderedPool</code> helps us to improve performance of <code class="language-plaintext highlighter-rouge">AllocationGroup</code>s by making access to distinct groups cache coherent.</p><p>One of the important questions that I asked myself was: how to make <code class="language-plaintext highlighter-rouge">AllocationGroup</code> construction and management as convenient as possible? I’ve came up with two fundamental principles:</p><ul><li><code class="language-plaintext highlighter-rouge">AllocationGroup</code> class works as handle to real allocation group, therefore <code class="language-plaintext highlighter-rouge">AllocationGroup</code> construction does not always results in construction of an actual allocation group. If allocation group with the same id already exists, new <code class="language-plaintext highlighter-rouge">AllocationGroup</code> will simply reference this implementation-level allocation group. This approach allows user to create <code class="language-plaintext highlighter-rouge">AllocationGroup</code> instances whenever he needs without worrying about referencing and duplicates: everything is resolved on implementation level.<li>Thread-local <code class="language-plaintext highlighter-rouge">AllocationGroup</code> stacks should be used to provide implicit parent selection unless parent group is selected explicitly. Stacks fit perfectly into this task: they provide intuitive interface for tasks like this. Also, stack usage allows to create connection between allocation groups from different modules without actually adding knowledge about each other to these modules. For example:</ul><div class="language-c++ highlighter-rouge"><div class="code-header"> <span data-label-text="C++"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
</pre><td class="rouge-code"><pre><span class="c1">// Storage module places its own allocation group on top before construction an object.</span>
<span class="k">auto</span> <span class="n">placeholder</span> <span class="o">=</span> <span class="n">GetAllocationGroup</span> <span class="p">().</span><span class="n">PlaceOnTop</span> <span class="p">();</span>
<span class="n">objectMapping</span><span class="p">.</span><span class="n">Construct</span> <span class="p">(</span><span class="n">object</span><span class="p">);</span>

<span class="c1">// Object expects right group to be placed on top during construction.</span>
<span class="k">class</span> <span class="nc">MyCustomObject</span> <span class="k">final</span>
<span class="p">{</span>
    <span class="c1">// ...</span>
    <span class="n">Container</span><span class="o">::</span><span class="n">Vector</span><span class="o">&lt;</span><span class="n">StandardLayout</span><span class="o">::</span><span class="n">Patch</span><span class="o">&gt;</span> <span class="n">patches</span> <span class="p">{</span><span class="n">Memory</span><span class="o">::</span><span class="n">Profiler</span><span class="o">::</span><span class="n">AllocationGroup</span><span class="o">::</span><span class="n">Top</span> <span class="p">()};</span>
    <span class="c1">// ...</span>
<span class="p">};</span>
</pre></table></code></div></div><p>Now let’s get a quick look at <code class="language-plaintext highlighter-rouge">AllocationGroup</code> registration methods:</p><ul><li><code class="language-plaintext highlighter-rouge">Allocate</code> registers increase of reserved memory amount.<li><code class="language-plaintext highlighter-rouge">Acquire</code> registers transfer from reserved memory into used memory.<li><code class="language-plaintext highlighter-rouge">Release</code> registers transfer from used memory to reserved memory.<li><code class="language-plaintext highlighter-rouge">Free</code> registers decrease of reserved memory amount.</ul><p>As you can see, this API is tailored for allocators than deal with memory reservation, which is the case for most allocations inside <a href="https://github.com/KonstantinTomashevich/Emergence">Emergence</a>.</p><p>Now it’s time to have a look at low level capture API. It consists of two major parts:</p><ul><li><p><code class="language-plaintext highlighter-rouge">CapturedAllocationGroup</code> class, that represents state of specific allocation group at the moment when capture was started. User receives <code class="language-plaintext highlighter-rouge">CapturedAllocationGroup</code> of predefined root <code class="language-plaintext highlighter-rouge">AllocationGroup</code> that represents captured allocation group hierarchy and can be traversed like normal allocation group hierarchy.</p><li><p>Event model, that consists of <code class="language-plaintext highlighter-rouge">Event</code> structure, that contains all the info about one specific memory operation, and <code class="language-plaintext highlighter-rouge">EventObserver</code>, that provides API for reading new events and works as a mailbox: user can extract events in historical order at any moment. One important implementation detail is that all observers use shared event queue which makes event management complexity independent of observer count.</p></ul><p>To start capturing memory profiling data user just needs to call <code class="language-plaintext highlighter-rouge">Capture::Start</code> method, that will capture all <code class="language-plaintext highlighter-rouge">AllocationGroup</code>s and create <code class="language-plaintext highlighter-rouge">EventObserver</code> for observing everything that happened after capture. To make event sequence easier to analyze, special marker events are also supported: user can put markers with custom ids using <code class="language-plaintext highlighter-rouge">AddMarker</code> method. Markers are treated like usual memory operation events. Although this API is pretty simple and straightforward, it is powerful enough to be foundation for more complex and sophisticated top-level API.</p><p>One significant theme, that I missed above, is how profiling backend deals with multithreading. I’ve though about trying to use some elaborate solution for this, but in the end I’ve decided to use one shared spin lock for all profiling-related operations. And it’s not as clumsy as it may sound: all profiling methods are already tailored to be as quick and small as possible, therefore lightweight spin lock looks like a perfect fit here.</p><h4 id="runtime-tracking-with-serialization-support"><span class="mr-2">Runtime tracking with serialization support</span><a href="#runtime-tracking-with-serialization-support" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4><p>Profiling backend provides API for retrieving data, but retrieving is not enough: we need a library that manages profiling data and provides tools to analyze and serialize this data. That’s the goal of <a href="https://github.com/KonstantinTomashevich/Emergence/tree/e8c37b6/Library/Public/MemoryRecording">Emergence::MemoryRecording library</a>. Its API provides user with ability to:</p><ul><li>Examine state of any allocation group at any moment of time provided this moment is inside profiling track.<li>Read all events inside profiling track in historical order.<li>Serialize and deserialize profiling tracks.<li>Capture profiling tracks at runtime.</ul><p>The most important part of <a href="https://github.com/KonstantinTomashevich/Emergence/tree/e8c37b6/Library/Public/MemoryRecording">Emergence::MemoryRecording library</a> is <code class="language-plaintext highlighter-rouge">Track</code> class, that stores full profiling track data and provides an API to iterate over that data and fetch allocation group states. That means that <code class="language-plaintext highlighter-rouge">Track</code> plays both the role of data storage and data provider.</p><p>As data storage, <code class="language-plaintext highlighter-rouge">Track</code> stores all profiling events in linked list, backed by pool allocator. For algorithmic convenience initial state of captured groups is also provided as group declaration events. We need this type of events to store information data about newly found allocation groups, otherwise we would need to duplicate this information in every operation event. So, if this additional event type is already needed, why not use it to save initial state too?</p><p>As data provider, <code class="language-plaintext highlighter-rouge">Track</code> provides state of any allocation group through <code class="language-plaintext highlighter-rouge">RecordedAllocationGroup</code> class instances. This class mimics <code class="language-plaintext highlighter-rouge">CapturedAllocationGroup</code>, but its instances are managed and update by owner <code class="language-plaintext highlighter-rouge">Track</code>. Time selection is done through movement of current event iterator using <code class="language-plaintext highlighter-rouge">MoveToPreviousEvent</code> and <code class="language-plaintext highlighter-rouge">MoveToNextEvent</code> methods. This approach is more universal than direct selection of time, because it allows iteration over all events without worrying about how they are separated by time. Also, it allows user to user to observe state of memory after any operation even if two operations are separated by very small amounts of time like 1 microsecond.</p><p>But how to populate <code class="language-plaintext highlighter-rouge">Track</code> with profiling data? There are two ways to do it: capture data at runtime using <code class="language-plaintext highlighter-rouge">RuntimeReporter</code> or load data from stream using <code class="language-plaintext highlighter-rouge">StreamDeserializer</code>. <code class="language-plaintext highlighter-rouge">RuntimeReporter</code> session is initialized through <code class="language-plaintext highlighter-rouge">Begin</code> method that accepts <code class="language-plaintext highlighter-rouge">Track</code> pointer and reference to captured root group, that will be converted into group declaration events for whole hierarchy. Then it expects user to pass events from <code class="language-plaintext highlighter-rouge">EventObserver</code> to <code class="language-plaintext highlighter-rouge">RuntimeReporter</code> through <code class="language-plaintext highlighter-rouge">ReportEvent</code> method whenever user wants to update <code class="language-plaintext highlighter-rouge">Track</code>. Session could be ended through the <code class="language-plaintext highlighter-rouge">End</code> method and after that <code class="language-plaintext highlighter-rouge">RuntimeReporter</code> could be reused. <code class="language-plaintext highlighter-rouge">StreamDeserializer</code> follows the session pattern: it requests track and stream pointers in <code class="language-plaintext highlighter-rouge">Begin</code> and parses events one-by-one using <code class="language-plaintext highlighter-rouge">TryReadNextEvent</code> method. One-by-one parsing is especially important when profiling tracks are quite long: it allows to spread data loading to several frames and by doing so avoid freezing tool that loads this profiling track. And due to instrumental profiling tracks usually grow quite fast, so it is important to avoid reading everything at once.</p><p>Serialization is done through <code class="language-plaintext highlighter-rouge">StreamSerializer</code>, that kind of mimics <code class="language-plaintext highlighter-rouge">RuntimeReporter</code>, but uses output stream as target instead of <code class="language-plaintext highlighter-rouge">Track</code> instance. Its <code class="language-plaintext highlighter-rouge">Begin</code> method accepts pointer to output stream and reference to captured root group. Then serialization is done using <code class="language-plaintext highlighter-rouge">SerializeEvent</code> method that takes profiling event as parameter and creates group declaration event for profiling track automatically if it is needed. One-by-one serialization is used for flexibility: user can limit how much time is spent serializing profiling data.</p><p>To sum up, <a href="https://github.com/KonstantinTomashevich/Emergence/tree/e8c37b6/Library/Public/MemoryRecording">Emergence::MemoryRecording</a> provides high-level API for working with profiling data, including state playback and serialization.</p><h4 id="client-application"><span class="mr-2">Client application</span><a href="#client-application" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4><p>I’ve created a <a href="https://github.com/KonstantinTomashevich/Emergence/tree/e8c37b6/Executable/MemoryRecordingClient">client application</a> for viewing serialized profiling tracks:</p><p><img data-src="/assets/img/EmergenceMemoryManagement/MemoryRecordingClient.png" alt="Memory recording client" data-proofer-ignore></p><ul><li>It shows memory usage flame graph with every group with used-to-total memory percentage.<li>Flame graph visual can be scaled and moved in any way user likes.<li>It shows timeline with markers. Markers with high frequency are shown only when timeline scale is low enough.<li>It shows list of events that are near current event, which allows user to easily jump to required event.<li>It allows user to select group on flame graph and view detailed info about this group and its children.</ul><p>Client application uses <a href="https://github.com/ocornut/imgui">ImGui</a> and <a href="https://www.libsdl.org/">SDL2</a>. It is a thin UI layer built on top of <a href="https://github.com/KonstantinTomashevich/Emergence/tree/e8c37b6/Library/Public/MemoryRecording">Emergence::MemoryRecording</a>, therefore it’s not really a lot to discuss here.</p><p>In future I’m planning to add automatic analyzers to client application that will track down common memory usage errors, that lead to performance drops. For example, underreservation, when there is not enough memory reserved for particular group and it always allocates new memory and them frees it, and overreservation, when too much memory is reserved for particular allocation group and this memory is never used to full extent.</p><h3 id="conclusion"><span class="mr-2">Conclusion</span><a href="#conclusion" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>As I said earlier, having consistent memory model and using a right approach for memory management in project is very important. That’s why I’ve spent a lot of time on designing and testing <a href="https://github.com/KonstantinTomashevich/Emergence">Emergence</a> memory-related libraries. I cannot say that these libraries are ideal as nothing is ideal in this world, but I believe that they’re good enough to support this project and its growth.</p><p>Hope you’ve enjoyed reading! If you have any suggestions, feel free to contact me through telegram or email.</p></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/emergence/'>Emergence</a>, <a href='/categories/development-log/'>Development Log</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/emergence/" class="post-tag no-text-decoration" >Emergence</a> <a href="/tags/c/" class="post-tag no-text-decoration" >C++</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=Emergence%3A+Memory+management+-+WHAT+KIND+OF+DEV+ARE+YOU&url=%2Fposts%2FEmergenceMemoryManagement%2F" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=Emergence%3A+Memory+management+-+WHAT+KIND+OF+DEV+ARE+YOU&u=%2Fposts%2FEmergenceMemoryManagement%2F" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://t.me/share/url?url=%2Fposts%2FEmergenceMemoryManagement%2F&text=Emergence%3A+Memory+management+-+WHAT+KIND+OF+DEV+ARE+YOU" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <a href="https://www.linkedin.com/sharing/share-offsite/?url=%2Fposts%2FEmergenceMemoryManagement%2F" data-toggle="tooltip" data-placement="top" title="Linkedin" target="_blank" rel="noopener" aria-label="Linkedin"> <i class="fa-fw fab fa-linkedin"></i> </a> <i id="copy-link" class="fa-fw fas fa-link small" data-toggle="tooltip" data-placement="top" title="Copy link" data-title-succeed="Link copied successfully!"> </i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted"><div class="access"><div id="access-lastmod" class="post"><div class="panel-heading">Recently Updated</div><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/EmergenceWhyIsThereNoEntitiesInCelerity/">Emergence: Why is there no entities in Celerity?</a><li><a href="/posts/ArrowToTheKneeEditingUnorderedMultisetItems/">Arrow to the Knee: Editing unordered_multiset items</a><li><a href="/posts/EmergenceInterpolatingTransform/">Emergence: Interpolating transform</a><li><a href="/posts/EmergenceWhat&Why/">Emergence: What & Why?</a><li><a href="/posts/HintGlobalInitializationOrder/">Hint: Global Initialization Order</a></ul></div><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/c/">C++</a> <a class="post-tag" href="/tags/emergence/">Emergence</a> <a class="post-tag" href="/tags/gamedev/">GameDev</a> <a class="post-tag" href="/tags/tutorials/">Tutorials</a> <a class="post-tag" href="/tags/ecs/">ECS</a> <a class="post-tag" href="/tags/algorithms/">Algorithms</a> <a class="post-tag" href="/tags/arrow-to-the-knee/">Arrow to the Knee</a> <a class="post-tag" href="/tags/cmake/">CMake</a> <a class="post-tag" href="/tags/containers/">Containers</a> <a class="post-tag" href="/tags/math/">Math</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"><div class="panel-heading pl-3 pt-2 mb-2">Contents</div><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div id="tail-wrapper" class="col-12 col-lg-11 col-xl-9 pl-3 pr-3 pr-xl-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/EmergenceWhat&Why/"><div class="card-body"> <em class="small" data-ts="1655560800" data-df="ll" > Jun 18, 2022 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Emergence: What & Why?</h3><div class="text-muted small"><p> I’ve been developing Emergence project for more than a year. Or two years, if you count a previous unfortunate attempt! I’ve decided to finally come out of the shadow and start writing about it. To...</p></div></div></a></div><div class="card"> <a href="/posts/EmergenceReflection/"><div class="card-body"> <em class="small" data-ts="1658573400" data-df="ll" > Jul 23, 2022 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Emergence: Reflection</h3><div class="text-muted small"><p> Reflection system is an important part of every engine, but there is no standard solution for that in C++: there are lots of libraries with their pros and cons. I’ve decided to write my own reflec...</p></div></div></a></div><div class="card"> <a href="/posts/EmergenceWhyIsThereNoEntitiesInCelerity/"><div class="card-body"> <em class="small" data-ts="1655977200" data-df="ll" > Jun 23, 2022 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Emergence: Why is there no entities in Celerity?</h3><div class="text-muted small"><p> Entity is the first of the three core principles of ECS design pattern. Nevertheless, I’ve decided that there should be no entities in Emergence ECS-like framework Celerity. I will tell you how I’v...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/EmergenceReflection/" class="btn btn-outline-primary" prompt="Older"><p>Emergence: Reflection</p></a><div class="btn btn-outline-primary disabled" prompt="Newer"><p>-</p></div></div><script type="text/javascript"> $(function () { const origin = "https://giscus.app"; const iframe = "iframe.giscus-frame"; const lightTheme = "light"; const darkTheme = "dark_dimmed"; let initTheme = lightTheme; if ($("html[data-mode=dark]").length > 0 || ($("html[data-mode]").length == 0 && window.matchMedia("(prefers-color-scheme: dark)").matches)) { initTheme = darkTheme; } let giscusAttributes = { "src": "https://giscus.app/client.js", "data-repo": "WhatKindOfDevAreYou/WhatKindOfDevAreYou.github.io", "data-repo-id": "R_kgDOHhaiVA", "data-category": "GitHub Pages Comments", "data-category-id": "DIC_kwDOHhaiVM4CPv5_", "data-mapping": "pathname", "data-reactions-enabled": "1", "data-emit-metadata": "0", "data-theme": initTheme, "data-input-position": "bottom", "data-lang": "en", "crossorigin": "anonymous", "async": "" }; let giscusScript = document.createElement("script"); Object.entries(giscusAttributes).forEach(([key, value]) => giscusScript.setAttribute(key, value)); document.getElementById("tail-wrapper").appendChild(giscusScript); addEventListener("message", (event) => { if (event.source === window && event.data && event.data.direction === ModeToggle.ID) { /* global theme mode changed */ const mode = event.data.message; const theme = (mode === ModeToggle.DARK_MODE ? darkTheme : lightTheme); const message = { setConfig: { theme: theme } }; const giscus = document.querySelector(iframe).contentWindow; giscus.postMessage({ giscus: message }, origin); } }); }); </script></div></div><footer class="row pl-3 pr-3"><div class="col-12 d-flex justify-content-between align-items-center text-muted pl-0 pr-0"><div class="footer-left"><p class="mb-0"> © 2022 <a href="https://github.com/KonstantinTomashevich">Konstantin Tomashevich</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/c/">C++</a> <a class="post-tag" href="/tags/emergence/">Emergence</a> <a class="post-tag" href="/tags/gamedev/">GameDev</a> <a class="post-tag" href="/tags/tutorials/">Tutorials</a> <a class="post-tag" href="/tags/ecs/">ECS</a> <a class="post-tag" href="/tags/algorithms/">Algorithms</a> <a class="post-tag" href="/tags/arrow-to-the-knee/">Arrow to the Knee</a> <a class="post-tag" href="/tags/cmake/">CMake</a> <a class="post-tag" href="/tags/containers/">Containers</a> <a class="post-tag" href="/tags/math/">Math</a></div></div></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a><div id="notification" class="toast" role="alert" aria-live="assertive" aria-atomic="true" data-animation="true" data-autohide="false"><div class="toast-header"> <button type="button" class="ml-2 ml-auto close" data-dismiss="toast" aria-label="Close"> <span aria-hidden="true">&times;</span> </button></div><div class="toast-body text-center pt-0"><p class="pl-2 pr-2 mb-3">A new version of content is available.</p><button type="button" class="btn btn-primary" aria-label="Update"> Update </button></div></div><script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No results found.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script src="https://cdn.jsdelivr.net/combine/npm/magnific-popup@1/dist/jquery.magnific-popup.min.js,npm/lozad/dist/lozad.min.js,npm/clipboard@2/dist/clipboard.min.js"></script> <script src="https://cdn.jsdelivr.net/combine/npm/dayjs@1/dayjs.min.js,npm/dayjs@1/locale/en.min.js,npm/dayjs@1/plugin/relativeTime.min.js,npm/dayjs@1/plugin/localizedFormat.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/js/bootstrap.bundle.min.js"></script> <script defer src="/app.js"></script>
